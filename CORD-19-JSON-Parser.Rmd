---
title: "CORD-19 Corpus"
author: University School of Medicine, Computational Bioscience Program, Biomedical
  Text Mining Group - Kevin Bretonnel Cohen
output:
  html_document: default
  pdf_document: default
  word_document: default
---

## TODO list

- Assemble set of test cases
- Clean up commented-out code DONE
- Put directory path in variable for ease of use by others

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("rjson")
library("rjson")

# set this to TRUE for lots of helpful debugging output, or to FALSE to suppress it
DEBUG <- TRUE

```

### Utility functions and variables to set

#### Global variables

```{r}
total.files.processed <- 0 # tracks the number of files that got processed, so that you can verify that it's what you expected
```

#### Output to a text file

```{r output.to.text.file}
# NB: if the directory already exists, it has to be manually emptied and deleted
output.directory <- "/Users/transfer/Dropbox/Scripts-new/cord19output/"
output.directory <- "/Users/transfer/Dropbox/Scripts-new/cord19output-titles/"
output.directory <- "/Users/transfer/Dropbox/Scripts-new/cord19output-abstracts/" # note that this doesn't currently include the titles
output.directory <- "/Users/transfer/Dropbox/Scripts-new/cord19output-papers/"
output.directory <- "/Users/transfer/Dropbox/Scripts-new/cord19output-papers-dev/"

dir.create(output.directory)
output.to.text.file <- function(textual.contents, file.name) {
# code adapted from https://stackoverflow.com/questions/2470248/write-lines-of-text-to-a-file-in-r
  
  file.name <- paste(file.name, ".txt", sep = "")
  fileConn <-file(file.name)
  writeLines(textual.contents, fileConn)
  close(fileConn)
}
```

#### How to navigate a single CORD-19 JSON file

```{r get.json.text}

# the argument json.contents is an rjson object containing the contents of a single file.
# the argument section.to.get tells whether to get an individual section, or all.
# values for section.to.get: TITLE, ABSTRACT, BODY, ALL
get.json.text <- function(json.contents, section.to.get) {
  
  textual.contents <- ""
  
  # TODO: validate that section.to.get is one that we support
  if (section.to.get == "TITLE" || section.to.get == "ALL") {
    if (DEBUG) {
      print(json.contents$metadata$title)
      textual.contents <- paste(textual.contents, json.contents$metadata$title)
    }
  }


  if (section.to.get == "ABSTRACT" || section.to.get == "ALL") {
    
    # the abstract is a list, so if there is an abstract, then the length of the list will be > 0
    if (length(json.contents$abstract) > 0) { 
    # each thing in the list is a separate chunk of the text of the abstract, which could be multiple paragraphs/sections
    # NB: weird iterator name j because I moved this from another location--refactor for clarity
    for (j in 1:length(json.contents$abstract)) {
      if (DEBUG) {
        print("*********%%%%%%%%%%% ABSTRACT ABSTRACT ABSTRACT %%%%%%%%%%%%%*********")
        print(json.contents$abstract[[j]]$text)
      }
      textual.contents <- paste(textual.contents, json.contents$abstract[[j]]$text)
    } # close for-loop through abstract contents
  } # close if-length-greater-than-0
  }
  
  if (section.to.get == "BODY" || section.to.get == "ALL") {
    # this for-loop goes through a single file and extracts the text of the body. need separate code for title, abstract (if there be one), etc.
    for (i in 1:length(json.contents$body_text)) {
      if (DEBUG) {
        print(paste("Body iterator value:", i))
        print(json.contents$body_text[[i]]$text)
      }
      textual.contents <- paste(json.contents$body_text[[i]]$text)
    } # close for-loop through body

  } # close if-body
  
  # global variable, so you don't need to return it
  total.files.processed <- total.files.processed + 1
  
  return(textual.contents)
} # close function definition

# no abstract
#json.contents <- fromJSON(file = "/Users/transfer/Dropbox/a-m/Corpora/cord19/noncomm_use_subset/ff34c772e37156609477e7f0fa4aba793171f806.json") # no abstract

# also no abstract
#json.contents <- fromJSON(file = "/Users/transfer/Dropbox/a-m/Corpora/cord19/noncomm_use_subset/ff5a79ed22ea416e6d89caad1cf0d83dbc741a4b.json") # 


# # NOT tests, just for validation during development
# # This is a file that I know has an abstract, so I used it for development
# json.contents <- fromJSON(file = "/Users/transfer/Dropbox/a-m/Corpora/cord19/noncomm_use_subset/025ed2caa0ae1ab7f04d3479116e6ed2a334938d.json") # 
# 
# get.json.text(json.contents, section.to.get = "TITLE")
# 
# get.json.text(json.contents, section.to.get = "ABSTRACT")
# 
# get.json.text(json.contents, section.to.get = "BODY")
# 
# get.json.text(json.contents, section.to.get = "ALL")
  
```

#### Process contents of a directory

```{r parse.directory.contents}

# NB NB NB: if there are more files in the directory than can be listed, you will get NAs for the file names. Consequently, I am limiting them by specifying their beginning, as well as their extension.  For example: ff*.json, rather than *.json
#directory.contents <- list.files("/Users/transfer/Dropbox/a-m/Corpora/cord19/noncomm_use_subset/", pattern = "ff*.json", full.names = TRUE)

parse.directory.contents <- function(directory, file.pattern) {
  directory.contents <- list.files(directory, pattern = file.pattern, full.names = TRUE)
  print(paste("Directory:", directory, "File pattern:", file.pattern))
  # TODO: keep track of this count so that you can make sure that you processed as many files as you expected to
 print(paste("Count of this subset of files:", as.character(length(directory.contents))))
print(directory.contents[1:10])

for (i in 1:length(directory.contents)) {
  json.contents <- fromJSON(file = directory.contents[i])
  if (DEBUG) {
    print(paste("Paper ID:", json.contents$paper_id))
  }
  paper.id <- json.contents$paper_id
  textual.contents <- get.json.text(json.contents, "TITLE")
  #textual.contents <- get.json.text(json.contents, "ABSTRACT")
  #textual.contents <- get.json.text(json.contents, "ALL")
  
  file.name <- paste(output.directory, paper.id, sep = "")
  output.to.text.file(textual.contents, file.name = file.name)
 
} # close for-loop
} # close function definition
```

# Go through the contents of the corpus

```{r go.through.the.corpus}
# there are a number of different subsets of the corpus--specify one of them
directory <- "/Users/transfer/Dropbox/a-m/Corpora/cord19/noncomm_use_subset/"

# There are too many files in some of these subsets to list, and when that
# happens, you get a bunch of NAs.  So, I'm just reading in a subset of the files at 
# a time.
# NB: don't expect all of these to necessarily return any files.
#file.pattern <- "ff*.json" # works in dev
# file.pattern <- "[a-e]*.json"
# file.pattern <- "[f-j]*.json"
# file.pattern <- "[k-o]*.json"
# file.pattern <- "[p-t]*.json"
# file.pattern <- "[u-z]*.json"
# file.pattern <- "0*.json"
# file.pattern <- "1*.json"
# file.pattern <- "2*.json"
# file.pattern <- "3*.json"
# file.pattern <- "4*.json"
# file.pattern <- "5*.json"
# file.pattern <- "6*.json"
# file.pattern <- "7*.json"
# file.pattern <- "8*.json"
# file.pattern <- "9*.json"

file.patterns <- c("[a-e]*.json",
                   "[f-j]*.json",
                   "[k-o]*.json",
                   "[p-t]*.json",
                   "[u-z]*.json",
                   "0*.json",
                   "1*.json",
                   "2*.json",
                   "3*.json",
                   "4*.json",
                   "5*.json",
                   "6*.json",
                   "7*.json",
                   "8*.json",
                   "9*.json")

#parse.directory.contents(directory, file.pattern)
parse.directory.contents(directory, file.patterns)

print(paste("Total files processed:", total.files.processed))
```

### Extra code snippets that I have tried

```{r extra.code, eval = FALSE}
#print(json.contents) # works
#print(json.contents$paper_id) # works
#print(json.contents$metadata$title) # works
#print(json.contents$metadata$authors) # works
#print(json.contents$body_text) # works, but not what I need
#print(json.contents[[1]]) # the paper ID
#print(json.contents$paper_id) # 
#print(json.contents$body_text) # works, but not what I need
#print(length(json.contents$body_text))

#print(json.contents$paper_id) # works
#print(json.contents$metadata$title) # works
# if (length(json.contents$abstract) > 0) { 
#   # each thing in the list is a separate chunk of the text of the abstract, which could be multiple paragraphs/sections
#   for (j in 1:length(json.contents$abstract)) {
#     print("*********%%%%%%%%%%% ABSTRACT ABSTRACT ABSTRACT %%%%%%%%%%%%%*********")
#     print(json.contents$abstract[[j]]$text)
#   }
# }

## this for-loop goes through a single file and extracts the text of the body. need separate code for title, abstract (if there be one), etc.
#for (i in 1:length(json.contents$body_text)) {
#  print(paste("Body iterator value:", i))
#  #print(json.contents$body_text[i])
#  print(json.contents$body_text[[i]]$text)
#}

```

## For reproducibility

```{r}
sessionInfo()
```


